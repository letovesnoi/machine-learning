{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "# Initialization cell\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_to_NPDtools = '/home/letovesnoi/work/tools/NPDtools-2.4.0-Linux/'\n",
    "\n",
    "data_dir = 'data'\n",
    "gnps_library = os.path.join(data_dir, 'GNPS-LIBRARY.mgf')\n",
    "# gnps_library = os.path.join(data_dir, 'tst.mgf')\n",
    "\n",
    "spectra_dir = os.path.join(data_dir, 'spectra')\n",
    "mols_dir = os.path.join(data_dir, 'mols')\n",
    "fthr = os.path.join(data_dir, 'data.fthr')\n",
    "\n",
    "reg_run_dir = os.path.join(data_dir, 'REG_RUN_GNPS')\n",
    "fdr0_tsv = os.path.join(reg_run_dir, 'regrun_fdr0_complete.tsv')\n",
    "spectra_rr_dir = os.path.join(data_dir, 'spectra_REG_RUN')\n",
    "reg_run_df = pd.read_csv(fdr0_tsv, sep=\"\\t\")\n",
    "grouped_df = reg_run_df.groupby(['SpecFile'])['LocalSpecIdx', 'Structure'].agg(list)\n",
    "fthr_rr = os.path.join(data_dir, 'data_rr.fthr')\n",
    "\n",
    "discrete_masses = np.linspace(0, 5000, num=50000, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# create directory for MGF files\n",
    "if os.path.exists(spectra_dir):\n",
    "    subprocess.call('rm -r {}'.format(spectra_dir), shell=True)\n",
    "os.mkdir(spectra_dir)\n",
    "\n",
    "# create directory for Molfiles\n",
    "if os.path.exists(mols_dir):\n",
    "    subprocess.call('rm -r {}'.format(mols_dir), shell=True)\n",
    "os.mkdir(mols_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_header(fin):\n",
    "    header = []\n",
    "    line = fin.readline()\n",
    "    while '=' in line:\n",
    "        ind = line.find('=')\n",
    "        header.append((line[:ind], line[ind + 1:].strip()))\n",
    "        line = fin.readline()\n",
    "    return header, line\n",
    "\n",
    "def get_spectrum(fin):\n",
    "    header, line = get_header(fin)\n",
    "    intensity = []\n",
    "    while line != 'END IONS\\n':\n",
    "        intensity.append(line.strip().split())\n",
    "        line = fin.readline()\n",
    "    return header, np.array(intensity, dtype='float64')\n",
    "\n",
    "def get_spectrum_id(header):\n",
    "    return header[18][1]\n",
    "\n",
    "def write_spectrum(header, intensity, spectrum_path):\n",
    "    with open(spectrum_path, 'a') as fout:\n",
    "        fout.write('BEGIN IONS\\n')\n",
    "        for key, value in header:\n",
    "            fout.write(key + '=' + value + '\\n')\n",
    "        for mass, abundance in intensity:\n",
    "            fout.write(str(mass) + ' ' + str(abundance) + '\\n')\n",
    "        fout.write('END IONS\\n')\n",
    "\n",
    "def split_mgf(mgf_library, spectra_dir, local_ids=None):\n",
    "    spectra_pathes = []\n",
    "    with open(mgf_library, 'r') as fin:\n",
    "        num_spectra = 0\n",
    "        while True:\n",
    "            line = fin.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            header, intensity = get_spectrum(fin)\n",
    "            if not local_ids:\n",
    "                spectrum_id = get_spectrum_id(header)\n",
    "            elif num_spectra in local_ids:\n",
    "                mgf_name = os.path.splitext(os.path.basename(mgf_library))[0]\n",
    "                spectrum_id = mgf_name + '_' + str(num_spectra)\n",
    "            else:\n",
    "                continue\n",
    "            spectra_pathes.append(os.path.join(spectra_dir, spectrum_id + '.mgf'))\n",
    "            write_spectrum(header, intensity, spectra_pathes[-1])\n",
    "            num_spectra += 1\n",
    "    # print('{} spectra'.format(num_spectra))\n",
    "    return spectra_pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23218c84d13f42fa9cf0afdfc5b201aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4666), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/spectra/CCMSLIB00000078897.mgf has no information about intensity\n"
     ]
    }
   ],
   "source": [
    "peptidic = 0\n",
    "smiles_errors = 0\n",
    "known = 0\n",
    "empty = 0\n",
    "\n",
    "def get_smiles(header):\n",
    "    return header[11][1]\n",
    "\n",
    "def get_mol(spectrum_path):\n",
    "    with open(spectrum_path, 'r') as fin:\n",
    "        fin.readline()\n",
    "        header, intensity = get_spectrum(fin)\n",
    "        molfile = os.path.join(mols_dir, get_spectrum_id(header) + '.mol')\n",
    "        # print('SMILES=' + get_smiles(header))\n",
    "        # print('SPECTRUMID=' + get_spectrum_id(header))\n",
    "        subprocess.call('molconvert mol:V3+H -s \\'{}\\' -o {}'.format(get_smiles(header), molfile), shell=True)\n",
    "    return molfile\n",
    "\n",
    "def is_structural(mgf_file):\n",
    "    global known\n",
    "    with open(mgf_file, 'r') as fin:\n",
    "        fin.readline()\n",
    "        header, intensity = get_spectrum(fin)\n",
    "        if get_smiles(header) == 'N/A' or get_smiles(header) == '':\n",
    "            return False\n",
    "        else:\n",
    "            known += 1\n",
    "            return True\n",
    "\n",
    "def is_peptidic(molfile):\n",
    "    global smiles_errors, peptidic\n",
    "    tmp_peptidic = os.path.join(data_dir, 'peptidic.tmp')\n",
    "    subprocess.call('{0}bin/print_structure {1} -C {0}share/npdtools/ --print_rule_fragmented_graph > {2}'.format(path_to_NPDtools, molfile, tmp_peptidic), shell=True)\n",
    "    with open(tmp_peptidic, 'r') as fin:\n",
    "        line = fin.readline()\n",
    "        subprocess.call('rm {}'.format(tmp_peptidic), shell=True)\n",
    "        if 'number of components' in line:\n",
    "            num_components = line.strip().split(':')[1][1:]\n",
    "        else:\n",
    "            smiles_errors += 1\n",
    "            print('{} contains an error'.format(molfile))\n",
    "            return -1\n",
    "    if int(num_components) > 3:\n",
    "        peptidic += 1\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_empty(mgf_file):\n",
    "    global empty\n",
    "    with open(mgf_file, 'r') as fin:\n",
    "        fin.readline()\n",
    "        header, intensity = get_spectrum(fin)\n",
    "        if len(intensity) != 0:\n",
    "            return False\n",
    "        else:\n",
    "            empty += 1\n",
    "            print('{} has no information about intensity'.format(mgf_file))\n",
    "            return True\n",
    "        \n",
    "def filter_spectra():\n",
    "    for mgf_file in tqdm(split_mgf(gnps_library, spectra_dir)):\n",
    "        # remove unknown spectrum\n",
    "        if not is_structural(mgf_file) or is_empty(mgf_file):\n",
    "            subprocess.call('rm {}'.format(mgf_file), shell=True)\n",
    "        else:\n",
    "            molfile = get_mol(mgf_file)\n",
    "            # remove non-peptidic data\n",
    "            is_pep = is_peptidic(molfile)\n",
    "            if is_pep == 0 or is_pep == -1:\n",
    "                subprocess.call('rm {}'.format(mgf_file), shell=True)\n",
    "                subprocess.call('rm {}'.format(molfile), shell=True)\n",
    "                \n",
    "filter_spectra()\n",
    "\n",
    "print('{} have a known structure'.format(known))\n",
    "print('{} have no information about intensity'.format(empty))\n",
    "print('{} SMILES contains an error'.format(smiles_errors))\n",
    "print('{} peptidic among structural, with non zero intensity, and with correct SMILES'.format(peptidic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_fthr(spectra_pathes, fthr, discrete_masses):\n",
    "    spectra_df = pd.DataFrame()\n",
    "    for mgf_file in tqdm(spectra_pathes):\n",
    "        with open(mgf_file, 'r') as fin:\n",
    "            fin.readline()\n",
    "            header, intensity = get_spectrum(fin)\n",
    "        id = os.path.splitext(os.path.basename(mgf_file))[0]\n",
    "        bins = pd.cut(intensity[:, 0], bins=discrete_masses, labels=False)\n",
    "        spectrum_df = pd.DataFrame({id: intensity[:, 1], 'binned': bins}).groupby(['binned']).sum().T\n",
    "        spectra_df = pd.concat([spectra_df, spectrum_df], sort=True)\n",
    "    spectra_df.columns = spectra_df.columns.astype(str)\n",
    "    spectra_df.reset_index().to_feather(fthr)\n",
    "    return fthr\n",
    "\n",
    "spectra_pathes = [os.path.join(spectra_dir, sp) for sp in os.listdir(spectra_dir)]\n",
    "\n",
    "fthr = get_fthr(spectra_pathes, fthr, discrete_masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for MGF files\n",
    "if os.path.exists(spectra_rr_dir):\n",
    "    subprocess.call('rm -r {}'.format(spectra_rr_dir), shell=True)\n",
    "os.mkdir(spectra_rr_dir)\n",
    "\n",
    "spectra_rr_pathes = []\n",
    "for index, row in grouped_df.iterrows():\n",
    "    mgf_path = os.path.join(reg_run_dir, os.path.splitext(index)[0] + '_filtered.mgf')\n",
    "    spectra_rr_pathes.extend(split_mgf(mgf_path, spectra_rr_dir, row['LocalSpecIdx']))\n",
    "    \n",
    "fthr_rr = get_fthr(spectra_rr_pathes, fthr_rr, discrete_masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip other cells except initialization and run this\n",
    "def get_df_from_files(fthr,  fthr_rr):\n",
    "    spectra_df = pd.read_feather(fthr)\n",
    "    del spectra_df['index']\n",
    "    spectra_df.columns = pd.to_numeric(spectra_df.columns)\n",
    "\n",
    "    spectra_rr_df = pd.read_feather(fthr_rr)\n",
    "    del spectra_rr_df['index']\n",
    "    spectra_rr_df.columns = pd.to_numeric(spectra_rr_df.columns)\n",
    "\n",
    "    df = pd.concat([spectra_df, spectra_rr_df], sort=True)\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    display(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = get_df_from_files(fthr,  fthr_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip it!  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test discretisation\n",
    "def plot_discretisation(tst_d_m=discrete_masses):\n",
    "    i = 0\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    for mgf_file in tqdm(spectra_pathes):\n",
    "        if i == 32:\n",
    "            break\n",
    "        ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "        with open(mgf_file, 'r') as fin:\n",
    "            fin.readline()\n",
    "            header, intensity = get_spectrum(fin)\n",
    "        id = os.path.splitext(os.path.basename(mgf_file))[0]\n",
    "        ax.plot(intensity[:, 0], intensity[:, 1])\n",
    "        bins = pd.cut(intensity[:, 0], bins=tst_d_m, labels=False)\n",
    "        tst_df = pd.DataFrame({'intensity': intensity[:, 1], 'binned': bins}).groupby(['binned'], as_index=False).sum()\n",
    "        tst_df['x'] = tst_df['binned'].transform(lambda b: tst_d_m[b])\n",
    "        ax.plot(tst_df.x, tst_df.intensity)\n",
    "        i += 1\n",
    "    return ax\n",
    "        \n",
    "plt.show(plot_discretisation())\n",
    "\n",
    "# Try different discretizations:\n",
    "discr_list = [100, 500, 1000, 5000, 10000]\n",
    "fthr_list = []\n",
    "fthr_rr_list = []\n",
    "df_list = []\n",
    "for discr_n in discr_list:\n",
    "    print('Discretization: {}\\n'.format(discr_n))\n",
    "    discr_m = np.linspace(0, 5000, num=discr_n, dtype='float64')\n",
    "    \n",
    "    fthr_d = os.path.join(data_dir, 'data.' + str(discr_n) + '.fthr')\n",
    "    fthr_list.append(get_fthr(spectra_pathes, fthr_d, discr_m))\n",
    "    \n",
    "    fthr_rr_d = os.path.join(data_dir, 'data_rr.' + str(discr_n) + '.fthr')\n",
    "    fthr_rr_list.append(get_fthr(spectra_rr_pathes, fthr_rr_d, discr_m))\n",
    "    \n",
    "    df_list.append(get_df_from_files(fthr_d,  fthr_rr_d))\n",
    "    \n",
    "    plt.show(plot_discretisation(discr_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "def get_spectrum_cyclicality(molfile):\n",
    "    tmp_cyclicality = os.path.join(data_dir, 'cyclicality.tmp')\n",
    "    subprocess.call('{0}bin/print_structure {1} -C {0}share/npdtools/ --print_structure > {2}'.format(path_to_NPDtools, molfile, tmp_cyclicality), shell=True)\n",
    "    with open(tmp_cyclicality, 'r') as fin:\n",
    "        cyclicality = fin.readline().strip()\n",
    "    subprocess.call('rm {}'.format(tmp_cyclicality), shell=True)\n",
    "    return cyclicality\n",
    "\n",
    "cycl_dict = {'linear': 0, 'cyclic': 1, 'b-cyclic': 2, 'branch-cyclic': 2, 'complex': 3}\n",
    "\n",
    "def get_labels(mols_dir):\n",
    "    labels = []\n",
    "    for molfile in tqdm(os.listdir(mols_dir)):\n",
    "        cyclicality = get_spectrum_cyclicality(os.path.join(mols_dir, molfile))\n",
    "        labels.append(cycl_dict[cyclicality])\n",
    "    return labels    \n",
    "\n",
    "def get_labels_rr(grouped_df):\n",
    "    labels = []\n",
    "    for index, row in grouped_df.iterrows():\n",
    "        labels.extend([cycl_dict[cyclicality] for cyclicality in row['Structure']])\n",
    "    return labels\n",
    "\n",
    "labels = get_labels(mols_dir) + get_labels_rr(grouped_df)\n",
    "\n",
    "print('{} linear'.format(labels.count(0)))\n",
    "print('{} cyclic'.format(labels.count(1)))\n",
    "print('{} branch-cyclic'.format(labels.count(2)))\n",
    "print('{} complex'.format(labels.count(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove complex and branch-cyclic classes\n",
    "nl = np.array(labels)\n",
    "criteria = np.logical_or(nl == 0, nl == 1) \n",
    "l_2 = nl[criteria]\n",
    "df_list_2 = [dataframe[criteria] for dataframe in df_list]\n",
    "df_2 = df[criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "choosen_df = df_list_2[0]\n",
    "\n",
    "X = choosen_df.to_numpy().astype('float32')\n",
    "y = np.array(l_2).astype('float32')\n",
    "\n",
    "display(choosen_df)\n",
    "\n",
    "X_train, X_test, train_binary_labels, test_binary_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_3d = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_3d = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = len(np.unique(train_binary_labels))\n",
    "y_train = keras.utils.to_categorical(train_binary_labels, num_classes)\n",
    "y_test = keras.utils.to_categorical(test_binary_labels, num_classes)\n",
    "\n",
    "print(X_train_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "for dataframe in df_list_2:\n",
    "    kmeans_pred = KMeans(n_clusters=2, random_state=42).fit_predict(X)\n",
    "    unique, counts = np.unique(kmeans_pred, return_counts=True)\n",
    "    print('Kmeans predictions:', dict(zip(unique, counts)))\n",
    "\n",
    "#     gmm_pred = GaussianMixture(n_components=2, covariance_type='full', random_state=42).fit_predict(X)\n",
    "#     unique, counts = np.unique(gmm_pred, return_counts=True)\n",
    "#     print('GMM predictions:', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# C, kernel, degree, gamma\n",
    "# parameters = {'kernel': ['poly', 'rbf'], 'gamma': [4, 16, 32], 'degree': [2, 4]}\n",
    "# svc = SVC(class_weight='balanced')\n",
    "# svc_clf = GridSearchCV(svc, parameters, cv=5, scoring=make_scorer('roc_auc'))\n",
    "svc_clf = SVC(class_weight='balanced')\n",
    "svc_clf.fit(X_train, train_binary_labels)\n",
    "# print(svc_clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "cnn_clf = Sequential()\n",
    "# model.add(Conv2D(filters=4, kernel_size=4, padding='same', activation='relu', input_shape=(1, 23325, 1)))\n",
    "# model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "# model.add(Conv2D(filters=4, kernel_size=4, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(1,2)))\n",
    "cnn_clf.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu', \n",
    "                   input_shape=(X_train_3d.shape[1], 1)))\n",
    "cnn_clf.add(MaxPooling1D(pool_size=2))\n",
    "cnn_clf.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "cnn_clf.add(MaxPooling1D(pool_size=2))\n",
    "cnn_clf.add(Dropout(0.3))\n",
    "cnn_clf.add(Flatten())\n",
    "cnn_clf.add(Dense(64, activation='relu'))\n",
    "cnn_clf.add(Dropout(0.4))\n",
    "cnn_clf.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnn_clf.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "w = dict(enumerate(class_weight.compute_class_weight('balanced', np.unique(train_binary_labels), train_binary_labels)))\n",
    "print('class weight = ', w, '\\n')\n",
    "hist = cnn_clf.fit(X_train_3d, y_train, batch_size=32, epochs=25, validation_split=0.2, \n",
    "                 callbacks=[checkpointer], verbose=2, shuffle=True, class_weight=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "cnn_clf.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "def evaluate_imbalanced(clf):\n",
    "    type_clf = type(clf).__name__\n",
    "    if type_clf == 'Sequential':\n",
    "        x = X_test_3d\n",
    "    else:\n",
    "        x = X_test\n",
    "    y_pred = clf.predict(x)\n",
    "    if type_clf != 'SVC':\n",
    "        pred_binary_labels = np.argmax(y_pred, axis=1)\n",
    "        y_score = y_pred[:, 1]\n",
    "    else:\n",
    "        pred_binary_labels = y_pred\n",
    "        y_score = y_pred\n",
    "    tn, fp, fn, tp = confusion_matrix(test_binary_labels, pred_binary_labels).ravel()\n",
    "    print('{name} TN = {tn}, {name} FP = {fp}, {name} FN = {fn}, {name} TP = {tp}'.\n",
    "          format(tn=tn, fp=fp, fn=fn, tp=tp, name=type_clf))\n",
    "    fpr, tpr, thresholds = roc_curve(test_binary_labels, y_score)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return fpr, tpr, auc_score\n",
    "\n",
    "\n",
    "fpr_d, tpr_d, auc_d = evaluate_imbalanced(dummy_clf)\n",
    "fpr_cnn, tpr_cnn, auc_cnn = evaluate_imbalanced(cnn_clf)\n",
    "fpr_svc, tpr_svc, auc_svc = evaluate_imbalanced(svc_clf)\n",
    "\n",
    "# Plot ROC curves for these two models\n",
    "plt.figure()\n",
    "plt.plot(fpr_d, tpr_d, lw=2, label='Dummy ROC curve (area = %0.2f)' % auc_d)\n",
    "plt.plot(fpr_cnn, tpr_cnn, lw=2, label='CNN ROC curve (area = %0.2f)' % auc_cnn)\n",
    "plt.plot(fpr_svc, tpr_svc, lw=2, label='SVM ROC curve (area = %0.2f)' % auc_svc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define text labels\n",
    "names = ['linear', 'cyclic', 'b-cyclic', 'complex']\n",
    "\n",
    "# plot a random sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "y_cnn = cnn_clf.predict(X_test_3d)\n",
    "for i, rc_i in enumerate(np.random.choice(X_test.shape[0], size=32, replace=False)):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])    \n",
    "    x = np.array([discrete_masses[int(bin_i)] for bin_i in choosen_df.columns.values.tolist()])\n",
    "    y = np.array(X_test[rc_i])  \n",
    "    y_mask = (y != 0)\n",
    "    ax.plot(x[y_mask], y[y_mask])\n",
    "    pred_idx = np.argmax(y_cnn[rc_i])\n",
    "    true_idx = int(test_binary_labels[rc_i])\n",
    "    ax.set_title(\"{} ({})\".format(names[pred_idx], names[true_idx]), \n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
